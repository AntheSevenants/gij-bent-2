---
title: "gij bent 2"
author:
  - name: Anthe Sevenants
    email: anthe.sevenants@kuleuven.be
    orcid: 0000-0002-5055-770X
    affiliations:
      - name: KU Leuven
  - name: Julie Nijs
    email: julie.nijs@kuleuven.be
    orcid: 000-0002-7421-9887
    affiliations:
      - name: KU Leuven
format:
  html:
    toc: true
  docx:
    toc: false
editor: source
title-block-banner: true
bibliography: references.bib
toc: true
toc-depth: 4
toc-location: left
tbl-cap-location: bottom
fig-cap-location: bottom
number-sections: true
reference-location: margin
csl: chicago-author-date.csl
df-print: kable
abstract: |
  TODO
execute:
  echo: false
---

```{r initialisation}
#| output: false
library(scales)
library(ggplot2)
library(broom)
library(dplyr)
library(tidycat)
library(emmeans)

formatn <- function(number) {
    format(round(as.numeric(number), 1), nsmall=0, big.mark=",")
}

formatd <- function(number, nsmall=2) {
    format(round(number, nsmall), nsmall=nsmall)
}

formatp <- function(number) {
    label_percent()(number)
}

suppress_gloss <- FALSE
```



```{r load-coefficients}
#| output: false

# Load the dataset
source("../analysis/0-common.R")

coefficients_full <- read.csv("../output/gij_bent_coefficients_two_genders.csv")

coefficients <- merge(x = coefficients_full %>% subset(substr(feature, 1, 1) != "_"),
               y = df %>% one_user_one_tweet,
               by.x = "feature",
               by.y = "user_id",
               all.x = TRUE)
coefficients$log_followers = log(coefficients$user_followers_count)
coefficients$log_following = log(coefficients$user_friends_count)
coefficients$log_tweet_count = log(coefficients$user_tweet_count)
coefficients$influence = log((coefficients$user_followers_count + 0.001) / (coefficients$user_friends_count + 0.001))

```


```{r regression-fit-format}
format_num_col <- function(p_value) {
  if (p_value < 0.01) {
    return("<0.01")
  } else {
    return(formatd(p_value, 4))
  }
}
format_num_col <- Vectorize(format_num_col)

format_table <- function(df) {
  df <- df %>% tidy %>% 
    tidy_categorical(m = df) %>% 
    filter(!is.na(term)) %>% 
    select(-c(reference, term, effect)) %>%
    mutate(variable = as.character(variable),
           level = as.character(level)) %>%
    mutate(level = ifelse(variable == level, "", level),
           variable = as.character(variable)) %>% 
    #group_by(variable) %>%
    #mutate(variable = ifelse(row_number() == 1, variable, "")) %>%
    #ungroup() %>%
    mutate(term = ifelse(level != "", paste0(variable, ": ", level), variable)) %>%
    select(-c(variable, level))
  df <- df[, c("term", "estimate", "std.error", "statistic", "p.value")]

  df$sig <- ifelse(df$p.value <= 0.05, "*", "")
  
  df$estimate <- df$estimate %>% formatd(2)
  df$std.error <- df$std.error %>% formatd(2)
  df$statistic <- df$statistic %>% formatd(2)
  df$p.value <- df$p.value %>% format_num_col()

  colnames(df) <- c("term", "coefficient", "std. error", "t value", "p value", " ")

  return(df)
}

format_posthoc_table <- function(df) {
  df <- df$contrasts %>% tidy()
  df$term <- NULL
  df$df <- NULL
  df$null <- NULL
  df$null.value <- NULL
  df$contrast <- gsub("[()]", "", df$contrast)
  df$contrast <- gsub("-", "â†”", df$contrast)

  df$sig <- ifelse(df$adj.p.value <= 0.05, "*", "")

  df$estimate <- df$estimate %>% formatd()
  df$std.error <- df$std.error %>% formatd()
  df$statistic <- df$statistic %>% formatd()
  df$adj.p.value <- df$adj.p.value %>% format_num_col()

  colnames(df) <- c("contrast", "coefficient", "std. error", "t value", "p value", "")

  return(df)
}
```

## Introduction {#sec:introduction}

One of the key ideas from usage-based linguistics is that language is not a system that exists just "by itself". Rather, it is widely accepted within this branch that language arises out of the many interactions that language users have with each other [@keller_language_1994]. As such, language becomes a "complex-adaptive system" [@ellis_what_2012;@kretzschmar_language_2015], a system without a single authoritative control, constructed through the simple yet numerous interactions of its components, language users. While each speaker of a language (be it Dutch, English or Maori) has their own personalised representation of the rules and constraints that they think make up that language, these representations have enough in common in order to warrant talking about a shared "code", or more broadly, a language.

When it comes to research of said shared code, things become more complicated. It is impossible for researchers to know the complete code of *all* language users in a language system. This situation forces models of language into necessary generalisations. Generalisation is a valid strategy, as most linguistic variation, when tallied at large, will lead to a Zipfian [@zipf_psycho-biology_1965] A-curve [as suggested by @kretzschmar_language_2015]. The make-up of this curve, with the most popular forms capturing most of the language use anyway, makes it so the "general" behaviour of language variation that is typically captured in corpora also represents a fair share of what would be the individual code of most language users. Of course, there are factors influencing what language forms are used,[^lects] but broadly speaking, this generalisation holds. We see this, for example, in probabilistic grammar, the branch of variation studies that investigates how variation reflects competing constraints on linguistic choices [@grafmiller_general_2018]. Still, on a theoretical level, it is regrettable that models of variation do not start from the lowest common denominator of this variation: the language user.

[^lects]: For example, one of the language varieties or "lects", defined as "dialects, regiolects, national varieties, registers, styles, idiolects, whatever" [@geeraerts_lectal_2005, 168]

Contrastively, the advent of social media offers a unique opportunity for variationist research. Social media platforms offer an insight into the language systems of a large number of people.  Whereas previously it was possible to gauge the linguistic profile of only a small group of people [e.g. @labov_study_1968;@milroy_belfast_1978], social media offer linguistic variation at an unprecedented scale.[^c-clamp] While one should not consider spoken and written social media as equivalent, social media language has nonetheless proven a useful proxy for the former [@vandekerckhove_perception_2007, 255]. In addition, social media data of course do not provide access to *all* of language for *all* users of a language system; not all utterances are made on social media, nor are all language users active on social media platforms. Nevertheless, social media platforms bring us closer to the idea of studying language *inside out*, starting from individual language users' variation, even if it is only for a single alternation among a subset of language users. This brings us to the first research question of this study:

1. What affordances does a focus on individual variation bring us in the context of alternation research, especially in contrast to traditional, aggregated alternation research?

[^c-clamp]: More recently, the release of the C-Clamp corpus [todo] offers a diachronic insight into the language use of Dutch-speaking writers from XXX to XXX. The historical nature of this corpus, however, limits its use for research into contemporary language variation phenomena.

[ @ Julie: misschien hier een stuk over het reeds bestaande onderzoek naar individuele variatie. hoeft niet veel te zijn maar nu staat er niets en dat is misschien niet top ]

Another aspect of of the complex-adaptive system of language are the connections between people. Humans are embedded in larger social networks, which are formed according to a so-called "power law". This means the network has a small number of people with a large number of connections, supplemented by many people who have relatively few connections [@barabasi_emergence_1999].

Linguistically, the effects of networks has been studied before [stuk Julie].

- leaders / loaners
- gedrag van centrale figuren
- alle andere dingen die interessant zouden kunenn zijn

Except for small-scale studies [e.g. @labov_study_1968;@milroy_belfast_1978], it has been impossible to get an elaborate insight into the social relationships of people on a large scale, let alone how these relationships relate to language. Again, social media offer an opportunity here. While it is not practical to get a full network of *all* social media users, we *can* get information on how "connected" a particular user is. Through metrics like "followers" and "following", we know how many connections social media users have. This allows us to get an idea of the centrality of a user in the larger social media network, even if we do not know the full network itself. This brings us to the second research question in this study:

2. How can we leverage the network implicit in social media data to learn more about the spread of linguistic innovations?

To answer the two research questions stated above, we follow up on a study by Sevenants [@sevenants_zijt_2024] about *gij bent*, a linguistic innovation concerning the second person of 'to be' in Colloquial Belgian Dutch (CBD). To compute the individual variation of different language users, we will use elastic net regression, a technique suited to determining individual variation. First, we will introduce the *gij bent* CBD linguistic innovation. Then, we will introduce the dataset and describe how we modelled the linguistic profiles of the individual users with regard to this innovation using elastic net, and why we need this specific technique to answer the questions we have in this study. Next, we will show the results of our analyses, and discuss what consequences they have for usage-based alternation research in general.

## The case of *gij bent*

This study focusses on *gij bent*, an innovation within Colloquial Belgian Dutch (CBD). Before we explain what this innovation is about, we will first explain the general language situation of Dutch in Belgium.

### Dutch in Belgium

Dutch as it is spoken in Belgium has evolved strongly since the second half of the 20^th^ century. In the largest part of the 20^th^ century, the language situation of Dutch in Flanders, the Dutch-speaking part of Belgium, could best be described as a *diglossia* [@auer_europe_2005]. This means that the Dutch was characterised by a dichotomy between standard language on the one hand, and dialects on the other hand. These two were the language modes available to speakers of Dutch. A large-scale language policy campaign at the timed attempted to teach those speakers who mastered only their local dialect the standard language. While these efforts were well intended, the imposition of a "foreign" standard language -- the standard was imported from the Netherlands -- were met with limited enthusiasm by language users in Flanders. However, this language campaign was not without effect, albeit not the intended one.

At the start of the 21^st^ century, it had become clear that Flanders was evolving into a new type of language situation: *diaglossia* [@auer_europe_2005]. In between the dialects and standard language, new language types had appeared, among which so-called "regiolects" (above the dialects) and "regional standards" (below standard language). More generally, however, a new term was coined: *tussentaal*, which roughly translates to "interlanguage". In this article, we will use the term defined by TODO, "Colloquial Belgian Dutch" or CBD.

The new variant CBD is characterised by being hard to define. In general, it is best described as a "standard-adjacent", colloquial form of Belgian Standard Dutch, with both general Flemish elements and region-specific features added to it on all levels (phonology, morphology, syntax etc.). The presence of region-specific features means that CBD is not a monolithic language variety, but rather sounds different across all places in Flanders. This inherent variability is intrinsic to its linguistic identity, but frustrating to linguists, who have been trying to come up with "defining features" for decades [todo citaties Zenner].

### *gij bent*

Traditionally in Flanders, if one wishes to say "you are" in an informal way, they would say *gij zijt*. *Gij* marks the informal second person pronoun that is typical to most Flemish dialects. *Zijt* is a historic form of *zijn* 'to be' that is now exclusively used with this pronoun. If one wanted to say "you are" in a formal way (i.e. in standard language), they would say *jij bent*. *Jij* marks the non-polite, yet formal second person pronoun in Flanders. *Jij* is more formal than *gij* because the *jij* pronoun is actually a Netherlandic form that, because it is foreign, has a different status than *gij*. *Bent* is the conjugated form that goes along with *jij*. It is also imported from the Netherlands.

It is clear, then, that these two forms are distinctly different from each other. However, in CBD, a blend of these two forms has appeared: *gij bent*. It combines the *gij* pronoun from *gij zijt* with the *bent* conjugation known from standard language. *Gij bent* is a quite literal example of the diaglossia situation, as it combines *gij* and *bent* from polar opposites of the language spectrum and meets somewhere in the middle.

Research by @sevenants_zijt_2024 has shown that *gij bent* most likely originated in dialects from the northern Antwerp province in Flanders, and then spread to other parts of the Brabantian dialect area.[^brabants] The reason for the spread from this area is argued to lie in the function of *gij bent*. The *jij bent* from standard language might feel too formal, while the *gij zijt* from dialects might feel too blunt. *Gij bent* strikes a balance between the two: it has colloquial roots through Flemish *gij*, but benefits from the prestige associated with standard language [@impe_vlamingen_2007] through standard *bent*. In addition, both regional, formality and gender effects were found:

1. the use of *gij bent* is limited to the Brabant dialect region only
2. the use of *gij bent* is less likely in more informal contexts
3. the use of *gij bent* is more likely for women

[^brabants]: Brabants is the dialect area coinciding, mostly, with the Flemish provinces "Vlaams-Brabant" and "Antwerp". It is said to be the driving force behind CBD, but this claim is disputed [@ghyselen_verticale_2016].

While these conclusions are drawn from language use originating from social media, the analysis itself is very traditional. As in a standard corpus linguistic study, it generalises over all language at once, as well as all language users. This leads to blanket statements as the ones above. As argued before, there is nothing inherently wrong with this approach, but given the opportunities in social media data, a more bottom-up approach would be interesting. More specifically, such an approach would allow us to detect whether certain language users behave differently from what we would expect given their location or gender. These deviations from general expectations are now invisible in the generalising models. In addition, no account was taken of the network structure hidden in the data, which might reveal more about the forces and the direction this innovation will take in the future.

## Data and methodology

### Dataset

As this study is a follow-up on the *gij bent* study by @sevenants_zijt_2024, we will re-use the dataset used in that study. The dataset contains [TODO infix] social media posts from Belgium on the Twitter platform (now X). These tweets either contain the traditional *gij zijt* or the innovative *gij bent* construction. The tweets are tagged for the Flemish dialect region to which each tweet author belongs. In addition, gender information was estimated for each tweet author using *gender-from-name-r* [@sevenants_gender_2024]. Authors for whom gender could not be established were removed, to retain parity with @sevenants_zijt_2024. The dataset also contains a formality distinction for each tweet ("more formal", "more informal"), based on whether a tweet interacts with other people. If it does, the idea is that the tweet is conversation-like and thus more informal. Each tweet also has a unique (anonymised) identifier, so tweets can be grouped by author. This will prove especially useful for this study on individual variation, since we need several tweets in order to gauge the language use of a specific speaker. For each author, we also know many accounts they follow, and how many accounts they are followed by. This is a metric that is useful for our questions about network influences. For our analysis of individual variation, we retained only those authors who have at least 10 tweets in our dataset. We did this in order to guarantee a stable estimation of each speaker's language use. After all filtering operations, we were left with TODO tweets by TODO unique authors.

### Elastic net regression

To estimate the individual variation among our tweet authors, we would ideally have a quantitative measure which indicates the deviation of each user from the expected linguistic behaviour. Authors who do not deviate would be assigned a (near-)zero value, while those who *do* deviate would receive either a positive or negative value, depending on whether they exceed the expectations for their profiles, or actually go against it. In this way, our measure of individual variation truly expresses the peculiarities of each individual speaker.

In order to operationalise this computation of individual variation, we made use of elastic net regression [@friedman_regularization_2010]. Elastic net regression is an extension of more "traditional" regression techniques [discussed in @gries_most_2015]. Its main innovation is that it uses an extra "penalty" term, which prevents model coefficients, the values associated with model predictors, from growing too large. One could think of this as making the model *worse*, but on purpose. In practice, this model penalty is applied for two reasons. First, it attempts to prevent overfitting. Too few data points can skew the estimation of a coefficient, so the penalty is a means to attenuate predictions in such cases. Second, the model penalty can function as a way to do variable selection. With elastic net, a coefficient can be "punished" to the extent that it nears or equals to zero. With this, the predictor of that coefficient is disabled outright. We can use this behaviour to enter many predictors in the same analysis at once, and let the model decide which ones are actually interesting.

In addition, elastic net leverages "k-fold cross validation". This technique divides the data into several parts and iteratively uses different parts for training and testing the regression model. This practice also contributes towards general robustness and the prevention of overfitting. K-fold cross validation allows us to have hundreds of predictors in a single analysis, which is a useful property when we want to track a multitude of language users at the same time. Such a thing would be impossible with a regular regression analysis on the basis of mathematical intractability (i.e. with mixed models). For additional details on elastic net regression for linguistics, see @sevenants_elastic_to_appear.

In general, then, elastic net regression lends itself nicely to research into individual variation. With elastic net, we modelled the presence of either *zijt* (conservative) or *bent* (innovative) as a logistic response variable. In our model, we estimated coefficients for each language user separately by treating those language users as individual predictors. Because we also included all the predictors from @sevenants_zijt_2024 in our analysis, these more general predictors (gender, dialect region, distance from northern Antwerp, formality) form the "expectation" for each specific speaker. Due to the multifactorial control characteristic[^multifactoriality] of regression analysis, this makes it so each individual speaker's coefficient becomes a measure of the variation that is not explained on the basis of the more general predictor terms, i.e. the individual deviation or variation we expressed our desire for in the previous sections.

[^multifactoriality]: Multifactorial control means that the analysis takes all predictors into account at the same time. This guarantees that variation due to one predictor is not assumed to stem from another.

For an overview of all predictors included in our model, see @tbl-predictors.

|predictor|explanation|
|---|---|
|dialect\*|the dialect area the tweet poster belongs to ("West Flemish", "East Flemish", "Brabantian", "Limburgish")
|gender|the estimated gender of the tweet poster -- generated automatically|
|distance from northern Antwerp|the distance of the poster's location in km from the northern Antwerp area|
|formality|the formality of the tweet -- derived from whether the tweet author interacts with another user in the tweet|
|user_id\*|a unique (anonymised) identifier for the tweet author -- allows us to know which tweets belong to the same person|

: An overview of all predictors which will be used in the elastic net regression. Predictors marked with \* receive separate predictors for each level (for example, separate predictors for each tweet author).  {#tbl-predictors}

For our analysis, we used ElasticToolsR [@sevenants_elastic_2024], a package for the R language [@r_language_2021] which simplifies running elastic net regression models.

## Results

In this section, we will go over the results produced by our elastic net regression model. We will  first look at the predictors included in the previous study to ensure our model produces comparable results. Then, we will dive into the predictors describing the behaviour of the individual language users.

### Controlling predictors {#sec-controlling-predictors}

@tbl-other-coefficients gives an overview of the "control" coefficients that were included in order to have multifactorial control for the individual variation. Since the innovative *bent* variant was encoded as outcome "1", and the conservative *zijt* was encoded as outcome "0", positive coefficients mean a a correction towards the innovative variant, while negative corrections mean a correction towards the conservative variant. These corrections must be interpreted from the situation expressed in the intercept, a "reference situation" that is defined as follows:

- formal situation (no reply or interaction)
- at distance "0" from northern Antwerp
- for users assumed to be male

In general, the control variable results are comparable to the results from [mezelf]. The innovative *gij bent* is more popular in the Brabant dialect area (positive correction), and less popular in the other areas (negative corrections). We even see the same anomaly for the West-Flemish dialect area.[^anomaly] *gij bent* becomes less popular as we move away from northern Antwerp, and more informal tweets also correct towards the conservative *gij zijt* (albeit very slightly, todo). We still see the expected gender effect, where tweets assumed to come from women have a higher probability of the use of *gij bent*. Compared to @sevenants_zijt_2024, some predictors have more subtle effects. Especially the distance correction and the formality distinction correction are smaller. We assume these differences stem from (i) the coefficient attenuation from the elastic net penalty (ii) a difference in dataset size -- @sevenants_zijt_2024 used only one tweet per user because of issues with random effects, which we sidestep by using elastic net regression (iii) parts of the variation attributed to other predictors in  @sevenants_zijt_2024 will now be attributed to individual variation. Still, broadly speaking, the results remain comparable. Therefore, we can safely move on to the discussion of the individual variation.

[^anomaly]: The results for the West-Flemish dialect area need to be interpreted in conjunction with the "distance from northern Antwerp" parameter. The regression analysis assumes a zero distance from Antwerp from the intercept, but this does not make sense for dialect areas other than Brabant. Therefore, if we apply the extra corrections expressed in "distance from northern Antwerp", we get the expected negative correction towards the conservative form (`r 121 * -0.017`). Still, the *gij* pronoun is quite rare in this area, so the West-Flemish results should be treated with caution.

```{r #tbl-other-coefficients}
#| label: tbl-other-coefficients
#| tbl-cap: "Overview of the controlling predictors predictors, their values and whether they were retained by the elastic net regression" 
# All other coefficients start with an underscore
other_coefficients <- coefficients_full[coefficients_full$feature %>% substr(1,1) == "_",]
# Change "removed" to "retained"
other_coefficients$retained = ifelse(other_coefficients$coefficient == 0, "no", "yes")
# Friendly names
other_coefficients$feature <- gsub("_(.+)", "\\1", other_coefficients$feature)
other_coefficients$feature <- gsub("(dialect_)", "dialect: ", other_coefficients$feature)
other_coefficients$feature <- gsub("(gender_)", "gender: ", other_coefficients$feature)
other_coefficients$feature <- gsub("(reply_)", "reply: ", other_coefficients$feature)
other_coefficients$feature <- gsub("(is_)", " ", other_coefficients$feature)
other_coefficients$feature <- gsub("(_)", " ", other_coefficients$feature)
other_coefficients$feature <- gsub("(antwerp)", "Antwerp (km)", other_coefficients$feature)
other_coefficients$predictor <- other_coefficients$feature
other_coefficients$coefficient <- other_coefficients$coefficient %>% formatd(3)
# Only keep interesting columns
other_coefficients <- other_coefficients[, names(other_coefficients) %in% c("coefficient", "predictor", "retained")]
# Re-order
other_coefficients <- other_coefficients[,c(3, 1, 2)]
# Sort
other_coefficients$coefficient <- as.numeric(other_coefficients$coefficient)
other_coefficients <- other_coefficients[order(other_coefficients$coefficient,
                                               decreasing=TRUE),]
# Remove row indices
rownames(other_coefficients) <- NULL
# Output to document
other_coefficients
```

### Individual variation

In this section, we will go over the coefficients that were computed for each language user. We will first look at the variation patterns globally, and then zoom in on the differences between different groups of language users. We will also attempt to model the coefficients in order to find relations between them.

#### Global variation pattern

First, we will look at the coefficient globally. The density plot of the variation coefficients in @fig-general-density gives a global overview of the how each language user "deviates" from what is expected given their gender, location etc.. Negative coefficients on the left side of the plot show deviations of individual language users towards the conservative *gij zijt*. Positive coefficients on the right side of the plot show deviations of individual language users towards the innovative *gij bent*. The middle dotted line marks the zero coefficient, i.e. those who do not deviate from the expected norm. We see that there is a bi-modal distribution in the variation coefficients. The first distribution shows many slights corrections towards the conservative form (first bump). The second distribution shows a smaller number of larger corrections towards the innovative form (second bump). This bi-modal variation pattern would have remained invisible in a more traditional regression model.

Note that each of the two different distributions might not consist of a homogeneous type of people. For example, the innovative corrections might include people in regions where the innovative form is rarely used, and who use the innovative form nonetheless. At the same time, innovative corrections might also stem from people in an already innovative area who "out-innovate" the expectations, using the innovative form even more often than is expected. We will attempt to tease out this distinction in the next section.

```{r #fig-general-density}
#| fig-cap: A density plot describing the individual variation coefficients in our dataset. The left side of the plot (negative coefficients) shows corrections towards the conservative form, the right side of the plot (positive coefficients) shows corrections towards the innovative form.
coefficients %>%
  ggplot(aes(x = coefficient)) +
  geom_density(fill="#69b3a2", color="#e9ecef", alpha=0.5) +
  geom_vline(xintercept=0, color="black", linewidth=1, linetype="dotdash")
```

#### Variation patterns among groups

##### Gender

Next, we will look at the patterns of variation among different groups. @fig-gender-violin shows the distribution of variation coefficients between men and women. There are two key points. First, we see that men and women have comparable profiles, with the same bi-modal trend seen in the general coefficients overview. We will address this bi-modality in the section on dialect variation patterns.

Secondly, we see that the most extreme innovative corrections in the plot stem from men, while the most extreme conservative corrections stem from women. This is peculiar, in the sense that this pattern "reverses" what we know from from @sevenants_zijt_2024 and @sec-controlling-predictors. However, keep in mind that the plot shows *corrections* on top of *expectations*. Though there are general trends that dictate a certain preference for men or women, this does not mean that *all* individuals from that group follow that same pattern. @fig-gender-violin shows this reversal: there are ample outlier speakers who deviate from what is typically expected from their gender, and this also highlights the need to be cautious when making generalisations in this regard. At the same time, the distributions between men and women are still similar enough that we likely cannot speak of distinctly different profiles. We will come back to this in our regression model of the coefficients in section TODO.

```{r #fig-gender-violin}
#| fig-cap: A violin plot describing the individual variation coefficients for men and women. A wider figure means more data for that y value.
coefficients %>%
  ggplot(aes(x = gender, y = coefficient, fill = gender)) +
  geom_violin() +
  geom_hline(yintercept=0, color="black", linewidth=1, linetype="dotdash")
```

##### Dialect

Next, we look at the dispersion of variation by Flemish dialect region in @fig-region-violin. Here, we do not see a "reversal" pattern, in contrast to @fig-gender-violin.  There seem to be two variation profiles: a Brabant variation profile, and a non-Brabant variation profile. The Brabant variation profile shows how in the Brabant dialect region, there is  a slight preference for innovation at the upper end of the coefficient values, with declining coefficents towards conserative corrections. In the three non-Brabant regions, we see that there are some innovators, but they are generally few. In these dialects, the values gravitate towards more conservative corrections. With these results, we have an explanation for the bi-modal nature of @fig-general-density: the first distribution, centred *below* zero, consists mostly of language users from non-Brabant dialect areas who are even more conservative than we expect from their region, and therefore correct "downwards". The second distribution, centred *above* zero, consists mostly of eager innovators from the already innovative Brabant dialect area. As avid users of the innovative form, they correct "upwards" in our plots.

```{r #fig-region-violin}
#| fig-cap: A violin plot describing the individual variation coefficients by region. A wider figure means more data for that y value.
coefficients %>%
  ggplot(aes(x = dialect, y = coefficient, fill = dialect)) +
  geom_violin() +
  geom_hline(yintercept=0, color="black", linewidth=1, linetype="dotdash")
```

We see in @fig-region-violin that, while they are few, innovators in non-Brabant dialect areas *do* exist. One might wonder what the profile of these rare innovators is. Perhaps they they live close to the border in their specific dialect regions, and are therefore "atypically" innovative for their region. To answer this question, we built a Generalised Additive Model or GAM [@hastie_generalized_1987]. A GAM can fit smooth curves to "wavy" data. If extrapolated to two dimensions, it allows one to create "weatherman-like" heatmaps for linguistic data. In this case, we modelled the elastic net coefficients on the basis of the latitude and longitude values associated with the places in the profiles of the Twitter users, according to the following equation:

todo equation

We will immediately shift towards the visual interpretation of the GAM in TODO. Dark blue colours show corrections towards the conservative variant, whereas light yellow colours show corrections towards the innovative variant. Beware to keep in mind, however, that these corrections are to be interpreted against the expected behaviour in that specific dialect region. In the GAM plot, we see that the northern Antwerp region is specifically innovative in contrast to an already innovative dialect region, Brabant. This is expected from the results by @sevenants_zijt_2024. What is especially interesting given our interest in the innovators in the non-Brabant regions, is that we indeed see that areas closer to the Brabant border show corrections that tend more towards the innovative variant. In addition, we also see that there seems to be an additional horizontal diffusion pattern, where the more innovative variant seems to spread from east to west in the east and from west to east in the west. This pattern remained invisible in the original study. Computer simulations have shown that border-adjacent speakers can play an important role as gatekeepers of innovations, since their hybrid identity can form a "bridge" through which innovations can be passed on [@sevenants_neighbours_2021]. In a sense, the horizontal positive variation coefficient pattern shows the pathway that *gij bent* might take in the future in order to break through in these other dialect regions.

TODO figure

In general, then, we see that there are two trends in the variation coefficients. Firstly, for gender, we see a "reversal" pattern, where typical behaviour is not shared across the entire gender group. Secondly, we see a wave-like [@francois_trees_2014] horizontal diffusion pattern in the non-Brabant dialect regions, even in regions which, in the general analysis, are thought to be rather conservative. Though speakers are of course free to use whatever forms they want, how they deviate from expectations is not random. 

[violin plots]

#### Network effects

As mentioned in INTRODUCTION TODO, the networked aspect of social media data provides an opportunity for researchers to investigate which people use what variant, and what that says about the diffusion of a new variant. Since our dataset comes from the Twitter platform, we also dispose of metrics which define a user's relative popularity on the platform. The first metric, "Followers", tallies how many other users want to see a user's posts appear in their own social media feed. Users with a large number of followers have a broad reach, and therefore have the possibility to be influential in their language use. The second metric, "Following", states how many other people's posts a user wants to see in their social media feed. Users who follow a large number of other users have the opportunity of being exposed to a larger linguistic pallette -- though this need not necessarily be the case.

To assess the influence of the users in our dataset within the larger Twitter network, we devised a metric which is based on the ratio between "Followers" and "Following". The idea of the metric is that users who have a large number of followers, yet follow few people themselves, have a larger relative influence than users without this asymmetry. Our influence metric is shown in Equation TODO.

$$
\log{
  \frac{
    \text{\# followers} + 0.001
  } {
    \text{\# following} + 0.001
  }
}
$$

Our influence metric is based on the priming ratio from @sevenants_elastic_to_appear and hinges on logarithm and Laplace smoothing [@brysbaert_dealing_2013]. The logarithm is a key operation in order to compress the wide numeric range found in follower and following counts. Where some users have thousands of followers, some only have a few. The use of the logarithm scales this discrepancy down. In addition, we use Laplace smoothing in order to avoid division by zero, in the event that users do not follow other users. The mean influence value among our speakers is `r coefficients$influence %>% mean() %>% formatd()` (median `r coefficients$influence %>% median() %>% formatd()`). The boxplot in @fig-influence shows that our dataset generally consists of more influential figures, i.e. users who have more followers than they themselves follow people. This is expected, since [todo parlee over disparity tussen posters en lurkers].

```{r #fig-influence}
boxplot(coefficients$influence, horizontal = T)
```

In our case, we want to know how the language users who are thought to be influential in our network behave. Are they are the forefront of innovation, or are they conservative? Depending on what profile we find, we might be able to discern in what phase of diffusion the *gij bent* innovation is situated (see Section TODO).

To answer this question, we built a common linear regression model. We model the coefficients in term of the influence of the users, but we also supplement our analysis with the dialect and gender distinctions we discussed earlier. Bundling all these possible influences in the same model will ensure that we do not accidentally assign variation between language users to the wrong source. It will also function as an extra check for the results from Section TODO, as we will now be able to check statistically whether the distinctions we spotted in the visual exploration are statistically significant distinctions. @tbl-linear-predictors gives an overview of the predictors that were used in the linear regression model.

|predictor|explanation|
|---|---|
|dialect|the dialect area the tweet poster belongs to ("West Flemish", "East Flemish", "Brabantian", "Limburgish")
|gender|the estimated gender of the tweet poster -- generated automatically|
|influence|a metric expressing the relative influence of a language user within the Twitter network|

: An overview of all predictors used in the linear regression model. {#tbl-linear-predictors}

```{r #tbl-linear-predictors}
#| tbl-cap: "Results of the linear regression analysis. * indicates statistical significance"
fit <- lm(coefficient ~ gender + dialect + influence, data=coefficients %>% no_unknown_gender())
fit %>% format_table()
```

We will first go over the controlling variables we discussed earlier, and then move on to the influence predictor.

1. Intercept

First, we look at the intercept of the model. Just like in TODO, the intercept here expressed the "default" situation against which further corrections need to be understood. Here, the intercept expresses a language user ...

- ... from the Brabant dialect area
- ... who is assumed to be male
- ... with an influence of "zero"

Our intercept starts from a value of TODO, which shows a slight bias for innovative behaviour. All further corrections need to be understood relative to this value.

2. Gender

We see that the distinction between users who are thought to be male and users who are thought to be female does not reach the significance threshold. Therefore, the differences which we discussed in TODO are not different enough to the degree that they are actually distinct. Still, the fact that the *tendency* is clearly there is still interesting, and the reversal of the extreme values of course still holds.

3. Dialect area

Next, we also see that there are significant differences between the reference dialect area (Brabant) and all other dialect areas. As was already clear from the visual inspection of the corrections per dialect area, we see that in non-Brabant areas, the corrections tend towards the conservative form, whereas Brabant area corrections are mostly innovative.

In addition, we wanted to know whether there are also differences *between* the non-Brabant dialact areas. To investigate this, we ran a post-hoc analysis through emmeans [@emmeans]. In this post-hoc analysis, we check for each dialect area pair whether there are significant differences in individual variation between the two. We see in @tbl-posthoc-test that there are *no* further differences between the non-Brabant dialect areas. Our assessment of the two variation profiles was thus correct.

```{r tbl-posthoc-test}
#| tbl-cap: Results of the `emmeans` posthoc analysis for dialect area. * indicates statistical significance
posthoc <- emmeans(fit,
                   pairwise ~ dialect,
                   type="response",
                   weights="proportional")

posthoc %>% format_posthoc_table()
```

4. Network influence

Finally, we look at the network influence parameter. Recall that our influence predictor expresses the (im)balance between the "followers" and "following" metrics, with those users who are followed by more people than they follow themselves being attributed a larger influence. The regression table in @tbl-linear-predictors shows that, as our influence metric increases, so does the probability for the use of *gij bent*. This means that the more influential a speaker is in the Twitter network, the more likely they are to use the new, innovative *gij bent* form. [Todo Julie uitleg hoe en waarom dit zo is]

[network effect explanation]

## Conclusion

- [algemeen idee van de individuele variatie]
- [conclusies voor tussentaal]
- [idee dat je op deze manier ook kunt vaststellen in welke fase van de verspreiding een fenomeen zit]